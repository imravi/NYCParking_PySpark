{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('nyc_parking').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdata=spark.read.csv('/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading the data from common folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summons Number',\n",
       " 'Plate ID',\n",
       " 'Registration State',\n",
       " 'Issue Date',\n",
       " 'Violation Code',\n",
       " 'Vehicle Body Type',\n",
       " 'Vehicle Make',\n",
       " 'Violation Precinct',\n",
       " 'Issuer Precinct',\n",
       " 'Violation Time']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13|             7|             SUBN|       ME/BE|                 0|              0|         0852P|\n",
      "|    1413609545|  X20DCM|                NJ|2016-08-03|            40|              SDN|       TOYOT|                71|             71|         0215A|\n",
      "|    4628525523|  326SF9|                MA|2016-12-21|            36|               UT|         BMW|                 0|              0|         0758A|\n",
      "|    4627113330| HCA5464|                NY|2016-11-21|            36|             SUBN|       DODGE|                 0|              0|         1005A|\n",
      "|    4006478550| VAD7274|                VA|2016-10-05|             5|               4D|         BMW|                 0|              0|         0845A|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdata.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,countDistinct,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime,unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date,year,month,dayofmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|years|count(Issue Date)|\n",
      "+-----+-----------------+\n",
      "| 1972|                2|\n",
      "| 1973|                2|\n",
      "| 1974|                1|\n",
      "| 1976|                1|\n",
      "| 1977|                1|\n",
      "| 1984|                1|\n",
      "| 1985|                1|\n",
      "| 1990|                2|\n",
      "| 1991|                3|\n",
      "| 1994|                1|\n",
      "| 1996|                1|\n",
      "| 1997|                1|\n",
      "| 2000|              185|\n",
      "| 2001|                2|\n",
      "| 2002|                1|\n",
      "| 2003|                1|\n",
      "| 2004|                2|\n",
      "| 2005|                1|\n",
      "| 2006|                8|\n",
      "| 2007|               18|\n",
      "| 2008|                4|\n",
      "| 2009|                3|\n",
      "| 2010|               48|\n",
      "| 2011|               22|\n",
      "| 2012|               87|\n",
      "| 2013|               70|\n",
      "| 2014|              120|\n",
      "| 2015|              419|\n",
      "| 2016|          5368391|\n",
      "| 2017|          5431918|\n",
      "| 2018|             1057|\n",
      "| 2019|              472|\n",
      "| 2020|               22|\n",
      "| 2021|               22|\n",
      "| 2022|                4|\n",
      "| 2023|                5|\n",
      "| 2024|                3|\n",
      "| 2025|                6|\n",
      "| 2026|               24|\n",
      "| 2027|               50|\n",
      "+-----+-----------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdata.groupby(year(to_date(col('Issue Date'),'yyyy-MM-dd')).alias('years')).agg({'Issue Date':'count'}).sort('years').show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from the above table their is wide range years present but we are going to analize the data only for year 2017 as given in the question.\n",
    "- Filtering data only for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdata=nycdata.filter(year(to_date(col('Issue Date'),'yyyy-MM-dd'))==2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|years|count(Issue Date)|\n",
      "+-----+-----------------+\n",
      "| 2017|          5431918|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdata.groupby(year(to_date(col('Issue Date'),'yyyy-MM-dd')).alias('years')).agg({'Issue Date':'count'}).sort('years').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking if columns are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycdata.filter(col('Summons Number').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycdata.filter(col('Plate ID').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycdata.filter(col('Violation Time').isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Examine the data</h3>\n",
    "1] Find the total number of tickets for the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|count(DISTINCT Summons Number)|\n",
      "+------------------------------+\n",
      "|                       5431918|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdata.agg(countDistinct(col('Summons Number'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total no of tickets in year 2017 are 5431918."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2] Find out the number of unique states from where the cars that got parking tickets came."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------+\n",
      "|Registration State|count(Registration State)|\n",
      "+------------------+-------------------------+\n",
      "|                NY|                  4273951|\n",
      "|                NJ|                   475825|\n",
      "|                PA|                   140286|\n",
      "|                CT|                    70403|\n",
      "|                FL|                    69468|\n",
      "|                IN|                    45525|\n",
      "|                MA|                    38941|\n",
      "|                VA|                    34367|\n",
      "|                MD|                    30213|\n",
      "|                NC|                    27152|\n",
      "|                TX|                    18827|\n",
      "|                IL|                    18666|\n",
      "|                GA|                    17537|\n",
      "|                99|                    16055|\n",
      "|                AZ|                    12379|\n",
      "|                OH|                    12281|\n",
      "|                CA|                    12153|\n",
      "|                ME|                    10806|\n",
      "|                SC|                    10395|\n",
      "|                MN|                    10083|\n",
      "+------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdata.groupby('Registration State').agg({'Registration State':'count'}).sort('count(Registration State)',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see 99 as one of the Registration state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a numeric entry '99' in the column, which should be corrected. Replace it with the state having the maximum entries. Provide the number of unique states again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdata.withColumn('Registration State',when(col('Registration State')=='99','NY').otherwise(col('Registration State')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing the state with 99 and replacing it with state with max entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------+\n",
      "|Registration State|count(Registration State)|\n",
      "+------------------+-------------------------+\n",
      "|                NY|                  4290006|\n",
      "|                NJ|                   475825|\n",
      "|                PA|                   140286|\n",
      "|                CT|                    70403|\n",
      "|                FL|                    69468|\n",
      "|                IN|                    45525|\n",
      "|                MA|                    38941|\n",
      "|                VA|                    34367|\n",
      "|                MD|                    30213|\n",
      "|                NC|                    27152|\n",
      "|                TX|                    18827|\n",
      "|                IL|                    18666|\n",
      "|                GA|                    17537|\n",
      "|                AZ|                    12379|\n",
      "|                OH|                    12281|\n",
      "|                CA|                    12153|\n",
      "|                ME|                    10806|\n",
      "|                SC|                    10395|\n",
      "|                MN|                    10083|\n",
      "|                OK|                     9088|\n",
      "+------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.groupby('Registration State').agg({'Registration State':'count'}).sort('count(Registration State)',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Aggregation tasks</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1] How often does each violation code occur? Display the frequency of the top five violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+\n",
      "|Violation Code|count(Violation Code)|\n",
      "+--------------+---------------------+\n",
      "|            21|               768087|\n",
      "|            36|               662765|\n",
      "|            38|               542079|\n",
      "|            14|               476664|\n",
      "|            20|               319646|\n",
      "+--------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.groupby('Violation Code').agg({'Violation Code':'count'}).sort('count(Violation Code)',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2] How often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------------+\n",
      "|Vehicle Body Type|count(Vehicle Body Type)|\n",
      "+-----------------+------------------------+\n",
      "|             SUBN|                 1883954|\n",
      "|             4DSD|                 1547312|\n",
      "|              VAN|                  724029|\n",
      "|             DELV|                  358984|\n",
      "|              SDN|                  194197|\n",
      "+-----------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.groupby('Vehicle Body Type').agg({'Vehicle Body Type':'count'}).sort('count(Vehicle Body Type)',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above are the vehicle body's which get max tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|Vehicle Make|count(Vehicle Make)|\n",
      "+------------+-------------------+\n",
      "|        FORD|             636844|\n",
      "|       TOYOT|             605291|\n",
      "|       HONDA|             538884|\n",
      "|       NISSA|             462017|\n",
      "|       CHEVR|             356032|\n",
      "+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.groupby('Vehicle Make').agg({'Vehicle Make':'count'}).sort('count(Vehicle Make)',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above are the vehicle body with max tickets,Ford vehicle's have topped the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vehicle make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1] 'Violation Precinct' (This is the precinct of the zone where the violation occurred). Using this, can you draw any insights for parking violations in any specific areas of the city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------+\n",
      "|Violation Precinct|count(Violation Precinct)|\n",
      "+------------------+-------------------------+\n",
      "|                 0|                   925596|\n",
      "|                19|                   274445|\n",
      "|                14|                   203553|\n",
      "|                 1|                   174702|\n",
      "|                18|                   169131|\n",
      "|               114|                   147444|\n",
      "+------------------+-------------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.groupby('Violation Precinct').agg({'Violation Precinct':'count'}).sort('count(Violation Precinct)',ascending=False).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from the above table that area 19 is where the maximum violation of traffic rules happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2] 'Issuer Precinct' (This is the precinct that issued the ticket.)\n",
    "Here, you would have noticed that the dataframe has the'Violating Precinct' or 'Issuing Precinct' as '0'.These are erroneous entries. Hence, you need to provide the records for five correct precincts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------+\n",
      "|Issuer Precinct|count(Issuer Precinct)|\n",
      "+---------------+----------------------+\n",
      "|              0|               1078406|\n",
      "|             19|                266961|\n",
      "|             14|                200495|\n",
      "|              1|                168740|\n",
      "|             18|                162994|\n",
      "|            114|                144054|\n",
      "+---------------+----------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.groupby('Issuer Precinct').agg({'Issuer Precinct':'count'}).sort('count(Issuer Precinct)',ascending=False).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4] Find the violation code frequencies for three precincts that have issued the most number of tickets. Do these precinct zones have an exceptionally high frequency of certain violation codes? Are these codes common across precincts? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : From the above Issuer Precinct table we can see that 3 precincts with most no of tickets are 19,14 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt.createOrReplaceTempView('nyc_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count_violation|\n",
      "+---------------+\n",
      "|         266961|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(`Violation Code`) as count_violation from nyc_data where `Issuer Precinct` =19').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count_violation|\n",
      "+---------------+\n",
      "|         200495|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(`Violation Code`) as count_violation from nyc_data where `Issuer Precinct` =14').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count_violation|\n",
      "+---------------+\n",
      "|         168740|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(`Violation Code`) as count_violation from nyc_data where `Issuer Precinct` =1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We try to analyze Violation codes for these Precincts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|Violation Code|freq_violation|\n",
      "+--------------+--------------+\n",
      "|            46|         48445|\n",
      "|            38|         36386|\n",
      "|            37|         36056|\n",
      "|            14|         29797|\n",
      "|            21|         28415|\n",
      "|            20|         14629|\n",
      "|            40|         11416|\n",
      "|            16|          9926|\n",
      "|            71|          7493|\n",
      "|            19|          6856|\n",
      "+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as freq_violation from nyc_data where `Issuer Precinct` =19 group by `Violation Code` order by freq_violation desc ').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|Violation Code|freq_violation|\n",
      "+--------------+--------------+\n",
      "|            14|         38354|\n",
      "|            16|         19081|\n",
      "|            20|         15408|\n",
      "|            46|         12745|\n",
      "|            38|          8535|\n",
      "|            17|          7526|\n",
      "|            37|          6470|\n",
      "|            31|          5853|\n",
      "|            69|          5672|\n",
      "|            19|          5375|\n",
      "+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as freq_violation from nyc_data where `Issuer Precinct` =1 group by `Violation Code` order by freq_violation desc ').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|Violation Code|freq_violation|\n",
      "+--------------+--------------+\n",
      "|            14|         45036|\n",
      "|            69|         30464|\n",
      "|            31|         22555|\n",
      "|            47|         18364|\n",
      "|            42|         10027|\n",
      "|            46|          7679|\n",
      "|            19|          7031|\n",
      "|            84|          6743|\n",
      "|            82|          5052|\n",
      "|            40|          3582|\n",
      "+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as freq_violation from nyc_data where `Issuer Precinct` =14 group by `Violation Code` order by freq_violation desc ').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above tables with top 10 entries of Violation codes we can see that Precincts 19,14,1 have in common 14,19 and 46 Violation code's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5] Find out the properties of parking violations across different times of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|sum(CAST((Violation Time IS NULL) AS INT))|\n",
      "+------------------------------------------+\n",
      "|                                         0|\n",
      "+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select sum(cast(isNull(`Violation Time`) as int))  from nyc_data').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking if Violation code have any null values from the above output we can say no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split,substring,length,size,array,substring_index,lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Violation Time|\n",
      "+--------------+\n",
      "|           nan|\n",
      "|          0557|\n",
      "|           nan|\n",
      "|          0855|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|          0515|\n",
      "|          0316|\n",
      "|          0651|\n",
      "|          1037|\n",
      "|           nan|\n",
      "|          0446|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|           nan|\n",
      "|           nan|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select t1.`Violation Time` from (select `Violation Time`,length(`Violation Time`) as ln  from nyc_data) as t1 where t1.ln!=5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from above table certain violation time are null and do not come with AM or PM format,So replacing them with most common occuring time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      23|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) from (select `Violation Time`,length(`Violation Time`) as ln  from nyc_data) as t1 where t1.ln!=5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see the count of such data is small i,e 23 So we replace it with most common occuring time.Without replacing we cannot continue further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|   vl|  cnt|\n",
      "+-----+-----+\n",
      "|0836A|14492|\n",
      "|1136A|13808|\n",
      "|1140A|13546|\n",
      "|0936A|13128|\n",
      "|0940A|12763|\n",
      "|0906A|12641|\n",
      "|0840A|12497|\n",
      "|1145A|12235|\n",
      "|0945A|12193|\n",
      "|1138A|12077|\n",
      "|0910A|12041|\n",
      "|1142A|11928|\n",
      "|1139A|11880|\n",
      "|0938A|11843|\n",
      "|0839A|11762|\n",
      "|0845A|11748|\n",
      "|0806A|11721|\n",
      "|0939A|11706|\n",
      "|0941A|11656|\n",
      "|1137A|11644|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Time` as vl,count(*) as cnt from nyc_data group by vl order by cnt desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So the most common occuring time is 8:36 am. So we replace with this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('Violation Time',when(length(col('Violation Time'))!=5,'0836A').otherwise(col('Violation Time')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.where(length(col('Violation Time'))!=5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since we need to form the buckets of time,We only need the hour of the day not minutes.So we just extract the hours.\n",
    "- We first convert the 12hr time zone into 24hr time for only hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('Timestamp',substring(col('Violation Time'),5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the am or pm imfo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('hourofday',substring(col('Violation Time'),1,2).cast('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the hour of day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for 24 hour time zone we take the hours from 0 to 23.\n",
    "- So the am time if from 0hr to 11 and pm time is from 12  to 23.\n",
    "- if the pm time is 12:36 it is completely valid but not the am.We keep the PM time with 12hr same and add 12 to rest of hours of day.\n",
    "- for AM we keep all hours same except 12,we take it as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('hourofday',when((lower(col('Timestamp'))=='p') & (col('hourofday')!=12),col('hourofday')+12).otherwise(col('hourofday')))\n",
    "nycdataflt=nycdataflt.withColumn('hourofday',when((lower(col('Timestamp'))=='a') & (col('hourofday')==12),0).otherwise(col('hourofday')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+---------+---------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Timestamp|hourofday|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+---------+---------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|        A|       11|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13|             7|             SUBN|       ME/BE|                 0|              0|         0852P|        P|       20|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|         0015A|        A|        0|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         0525A|        A|        5|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|         0256P|        P|       14|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above sample we can see that we have successfuly converted hr in 24hr format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use bucketizer to create 6 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt.createOrReplaceTempView('nyc_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summons Number',\n",
       " 'Plate ID',\n",
       " 'Registration State',\n",
       " 'Issue Date',\n",
       " 'Violation Code',\n",
       " 'Vehicle Body Type',\n",
       " 'Vehicle Make',\n",
       " 'Violation Precinct',\n",
       " 'Issuer Precinct',\n",
       " 'Violation Time',\n",
       " 'Timestamp',\n",
       " 'hourofday']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycdataflt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+---------+---------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Timestamp|hourofday|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+---------+---------+\n",
      "|    1420359022| KXY414F|                NJ|2017-03-07|            46|             DELV|       CHEVR|                40|             40|         6815P|        P|       80|\n",
      "|    1420596238| FHM8683|                NY|2017-06-02|            21|              SDN|       ME/BE|               109|              0|         8715P|        P|       99|\n",
      "|    1404833780| HGR8521|                NY|2017-02-23|            38|              SDN|       HYUND|                19|            977|         5402P|        P|       66|\n",
      "|    1413587148| GNL1630|                NY|2017-01-21|            40|             SUBN|       CHEVR|                71|             71|         1305P|        P|       25|\n",
      "|    1419793974| GRH3693|                NY|2017-04-19|            21|              SDN|       NISSA|                60|              0|         7640P|        P|       88|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nycdataflt.where(col('hourofday')>24).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can still see some of the hours more that 24.This is because Violation time is not valid for these records.\n",
    "- So we replace these values with most common occuring hour of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|hourofday|   cnt|\n",
      "+---------+------+\n",
      "|        9|595631|\n",
      "|       11|574632|\n",
      "|       13|549287|\n",
      "|       12|510135|\n",
      "|        8|503869|\n",
      "|       10|489457|\n",
      "|       14|466068|\n",
      "|       15|314468|\n",
      "|       16|295983|\n",
      "|        7|270629|\n",
      "|       17|211173|\n",
      "|        6|121552|\n",
      "|       18|104284|\n",
      "|       21| 55322|\n",
      "|       20| 49221|\n",
      "|        1| 46069|\n",
      "|        0| 45701|\n",
      "|        5| 43154|\n",
      "|       22| 42540|\n",
      "|        2| 40312|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select hourofday,count(*) as cnt from nyc_data group by hourofday order by cnt desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that 9th hr is the most occuring one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|cnt|\n",
      "+---+\n",
      "| 55|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) as cnt from nyc_data where hourofday>=24').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Their are only 55 records with such defect,So we can replace with proper data without this we cannot use bucketizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('hourofday',when(col('hourofday')>=24,9).otherwise(col('hourofday')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt.createOrReplaceTempView('nyc_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|cnt|\n",
      "+---+\n",
      "|  0|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) as cnt from nyc_data where hourofday>=24').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=[0,4,8,12,16,20,24]\n",
    "bucket=Bucketizer(splits=splits,inputCol='hourofday',outputCol='buckets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hours [0-4) put in buckets 0.0.\n",
    "- hours [4-8) put in buckets 1.0.\n",
    "- hours [8-12) put in buckets 2.0.\n",
    "- hours [12-16) put in buckets 3.0.\n",
    "- hours [16-20) put in buckets 4.0.\n",
    "- hours [20-24] put in buckets 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=bucket.transform(nycdataflt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt.createOrReplaceTempView('nyc_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|buckets|    cnt|\n",
      "+-------+-------+\n",
      "|    2.0|2163644|\n",
      "|    3.0|1839958|\n",
      "|    4.0| 637540|\n",
      "|    1.0| 449881|\n",
      "|    5.0| 176360|\n",
      "|    0.0| 164535|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select buckets,count(*) as cnt from nyc_data group by buckets order by cnt desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding the 3 most commonly occuring Violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Violation Code|  cnt|\n",
      "+--------------+-----+\n",
      "|            21|36958|\n",
      "|            40|25867|\n",
      "|            78|15528|\n",
      "|            14|15400|\n",
      "|            20|12184|\n",
      "|             7|10168|\n",
      "|            46| 6648|\n",
      "|            85| 6351|\n",
      "+--------------+-----+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as cnt from nyc_data where buckets=0.0 group by `Violation Code` order by cnt desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Violation Code|  cnt|\n",
      "+--------------+-----+\n",
      "|            14|74114|\n",
      "|            40|60652|\n",
      "|            21|57897|\n",
      "|            20|43146|\n",
      "|            71|22116|\n",
      "|             7|18608|\n",
      "|            46|16414|\n",
      "|            19|16312|\n",
      "+--------------+-----+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as cnt from nyc_data where buckets=1.0 group by `Violation Code` order by cnt desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code|   cnt|\n",
      "+--------------+------+\n",
      "|            21|598094|\n",
      "|            36|348165|\n",
      "|            38|176571|\n",
      "|            14|149026|\n",
      "|            46|109716|\n",
      "|            71| 95559|\n",
      "|            20| 90569|\n",
      "|            40| 71063|\n",
      "+--------------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as cnt from nyc_data where buckets=2.0 group by `Violation Code` order by cnt desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code|   cnt|\n",
      "+--------------+------+\n",
      "|            36|286284|\n",
      "|            38|240721|\n",
      "|            37|167026|\n",
      "|            14|141177|\n",
      "|            46|124119|\n",
      "|            20|115729|\n",
      "|            71|103231|\n",
      "|            21| 74695|\n",
      "+--------------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as cnt from nyc_data where buckets=3.0 group by `Violation Code` order by cnt desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code|   cnt|\n",
      "+--------------+------+\n",
      "|            38|102855|\n",
      "|            14| 75902|\n",
      "|            37| 70345|\n",
      "|             7| 53626|\n",
      "|            46| 43155|\n",
      "|            20| 42583|\n",
      "|            71| 34710|\n",
      "|            40| 25440|\n",
      "+--------------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as cnt from nyc_data where buckets=4.0 group by `Violation Code` order by cnt desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Violation Code|  cnt|\n",
      "+--------------+-----+\n",
      "|             7|26293|\n",
      "|            40|22337|\n",
      "|            14|21045|\n",
      "|            38|20347|\n",
      "|            20|15435|\n",
      "|            46|12278|\n",
      "|            78| 9719|\n",
      "|            19| 8669|\n",
      "+--------------+-----+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as cnt from nyc_data where buckets=5.0 group by `Violation Code` order by cnt desc').show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above 6 tables we see that Violations codes 14,40 and 20 are the once which are appearing in all the tables within top 8 list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding the common time of the day when these Violations happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|buckets|   cnt|\n",
      "+-------+------+\n",
      "|    2.0|149026|\n",
      "|    3.0|141177|\n",
      "|    4.0| 75902|\n",
      "|    1.0| 74114|\n",
      "|    5.0| 21045|\n",
      "|    0.0| 15400|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select buckets,count(*) as cnt from nyc_data where `Violation Code`=14 group by buckets order by cnt desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|buckets|  cnt|\n",
      "+-------+-----+\n",
      "|    3.0|71825|\n",
      "|    2.0|71063|\n",
      "|    1.0|60652|\n",
      "|    0.0|25867|\n",
      "|    4.0|25440|\n",
      "|    5.0|22337|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select buckets,count(*) as cnt from nyc_data where `Violation Code`=40 group by buckets order by cnt desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|buckets|   cnt|\n",
      "+-------+------+\n",
      "|    3.0|115729|\n",
      "|    2.0| 90569|\n",
      "|    1.0| 43146|\n",
      "|    4.0| 42583|\n",
      "|    5.0| 15435|\n",
      "|    0.0| 12184|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select buckets,count(*) as cnt from nyc_data where `Violation Code`=20 group by buckets order by cnt desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above 3 tables we can see buckets 2 and 3,ie time 8am-12pm and 12pm-16pm is the time when max violations happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6] Seasonality in Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We divide the months based on the seasons,summer,winter,fall and winter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('monthofissue',month(to_date(col('Issue Date'),'yyyy-MM-dd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getseason(data):\n",
    "    if data==12 or data==1 or data==2: #Winter\n",
    "        return 1\n",
    "    elif data==3 or data==4 or data==5: #Spring\n",
    "        return 2\n",
    "    elif data==6 or data==7 or data==8: #Summer\n",
    "        return 3\n",
    "    elif data==9 or data==10 or data==11: #Fall\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons=udf(getseason,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt=nycdataflt.withColumn('seasons',seasons(col('monthofissue')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycdataflt.createOrReplaceTempView('nyc_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1] find the frequencies of tickets for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|seasons|  count|\n",
      "+-------+-------+\n",
      "|      2|2873383|\n",
      "|      1|1704690|\n",
      "|      3| 852866|\n",
      "|      4|    979|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select seasons,count(*) as count from nyc_data group by seasons order by count desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spring season has got max no of tickets and fall has least no of tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2] find the three most common violations for each of these seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code| count|\n",
      "+--------------+------+\n",
      "|            21|238183|\n",
      "|            36|221268|\n",
      "|            38|187386|\n",
      "|            14|142262|\n",
      "|            20| 97996|\n",
      "|            37| 97812|\n",
      "|            46| 95991|\n",
      "|            40| 86804|\n",
      "+--------------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as count from nyc_data where seasons=1 group by `Violation Code` order by count desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code| count|\n",
      "+--------------+------+\n",
      "|            21|402424|\n",
      "|            36|344834|\n",
      "|            38|271167|\n",
      "|            14|256397|\n",
      "|            46|173440|\n",
      "|            20|157122|\n",
      "|            37|151049|\n",
      "|            40|147408|\n",
      "+--------------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as count from nyc_data where seasons=2 group by `Violation Code` order by count desc').show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code| count|\n",
      "+--------------+------+\n",
      "|            21|127352|\n",
      "|            36| 96663|\n",
      "|            38| 83518|\n",
      "|            14| 77911|\n",
      "|            20| 64474|\n",
      "|            71| 45199|\n",
      "|            37| 44284|\n",
      "|            40| 42856|\n",
      "+--------------+------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as count from nyc_data where seasons=3 group by `Violation Code` order by count desc').show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above 3 table have top 5 violation codes almost same with position change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Violation Code|count|\n",
      "+--------------+-----+\n",
      "|            46|  231|\n",
      "|            21|  128|\n",
      "|            40|  116|\n",
      "|            14|   94|\n",
      "|            19|   57|\n",
      "|            20|   54|\n",
      "|            98|   50|\n",
      "|            50|   28|\n",
      "+--------------+-----+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as count from nyc_data where seasons=4 group by `Violation Code` order by count desc').show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All 4 seasons have 21,40,20 and 14 as the common violation code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1] Find the total occurrences of the three most common violation codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : From all the above analysis we can say 14,40 and 20 are the most common occuring Violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|total_occurrences|\n",
      "+-----------------+\n",
      "|          1073494|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) as total_occurrences from nyc_data where `Violation Code`=14 or `Violation Code`=40 or`Violation Code`=20').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the total occurrences of all 3 common violation codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2] find the total amount collected for the three violation codes with the maximum tickets. State the code that has the highest total collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|Violation Code| count|\n",
      "+--------------+------+\n",
      "|            21|768087|\n",
      "|            36|662765|\n",
      "|            38|542079|\n",
      "|            14|476664|\n",
      "|            20|319646|\n",
      "+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select `Violation Code`,count(*) as count from nyc_data group by `Violation Code` order by count desc').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 violation codes with max no of tickets are 21,36 and 38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page\">Violation code Fines.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|collection|\n",
      "+----------+\n",
      "|  42244785|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*)*55 as collection from nyc_data where `Violation Code`=21').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the code 21 we have fine in area Manhattan 96th St. & below $65 and all other area $45 taking the average comes $55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|collection|\n",
      "+----------+\n",
      "|  33138250|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*)*50 as collection from nyc_data where `Violation Code`=36').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the code 36 we have fine in area Manhattan 96th St. & below $50 and All other area $50 taking the average comes $50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|collection|\n",
      "+----------+\n",
      "|  27103950|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*)*50 as collection from nyc_data where `Violation Code`=38').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the code 21 we have fine in area Manhattan 96th St. & below $65 and all other area $35 taking the average comes $50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above tables we can see that 21 has highest collection compared to other 2 codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|total_collection_for_3|\n",
      "+----------------------+\n",
      "|            102.486985|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select (42244785+60242200)/1000000 as total_collection_for_3').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total collection in millions comes out to be 102.49mills for just 3 violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From all the above findings we can say that:\n",
    "- Most of the violations happen during 8 am to 4pm.\n",
    "- Max no of violations happen in spring season i,e in the months of march,april and may.\n",
    "- least no of violations happen in Fall season i,e in the months of Sep,Oct and Nov.\n",
    "- Most common violation codes in the various seasons and different time are 14,40 and 20.\n",
    "- Violation codes with max tickets are 21,36 and 38.\n",
    "- Fine collected from violations 21,36 and 38 during 2017 comes out to be 102.49 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
